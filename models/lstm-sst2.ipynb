{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"lstm_sst2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0cedafacfc7a4151b9050251ca0726df":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2fc4717a13424378b2fe43085c42c93a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_319ff408158241b7afb705e55b079609","IPY_MODEL_7931d6ef685742889ca65bf20ff1bc3d"]}},"2fc4717a13424378b2fe43085c42c93a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"319ff408158241b7afb705e55b079609":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_76c87573d66d4a99a123f4ba19493603","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0007674eb5434be181bc23dba8dfa73c"}},"7931d6ef685742889ca65bf20ff1bc3d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d7f30259b088435c926072b2e1b0506a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 621kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_82050b52082a44b5a051179169d0daa1"}},"76c87573d66d4a99a123f4ba19493603":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0007674eb5434be181bc23dba8dfa73c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d7f30259b088435c926072b2e1b0506a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"82050b52082a44b5a051179169d0daa1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/ronakdm/input-marginalization/blob/main/lstm_sst2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"n5UIHIwjbXUU","executionInfo":{"status":"ok","timestamp":1615900464983,"user_tz":240,"elapsed":10139,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}}},"source":["%%capture\n","!git clone https://github.com/ronakdm/input-marginalization.git"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_AXX1JWiVpH","executionInfo":{"status":"ok","timestamp":1615900465190,"user_tz":240,"elapsed":10334,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"8f25fdd7-3856-4d09-a204-6f089df0ce54"},"source":["%%bash\r\n","cd input-marginalization\r\n","git pull\r\n","cd .."],"execution_count":2,"outputs":[{"output_type":"stream","text":["Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mdt1j3SUihdj","executionInfo":{"status":"ok","timestamp":1615900507673,"user_tz":240,"elapsed":22501,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"e41cc739-0792-4067-f151-d6e7ee148729"},"source":["from google.colab import drive\r\n","drive.mount('/content/gdrive')\r\n","save_dir = \"/content/gdrive/My Drive/input-marginalization\""],"execution_count":5,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0ff8o_N7KjOa","executionInfo":{"status":"ok","timestamp":1615900511550,"user_tz":240,"elapsed":623,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}}},"source":["import pickle\n","import numpy as np\n","import time\n","import datetime\n","import random\n","import torch\n","import torch.nn as nn"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"quKITBFalxqo","executionInfo":{"status":"ok","timestamp":1615900514859,"user_tz":240,"elapsed":1565,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}}},"source":["import sys\r\n","sys.path.append(\"input-marginalization\")\r\n","\r\n","from utils import generate_dataloaders, train, test\r\n","from models import LSTM"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"0qxZMqGNKni8","executionInfo":{"status":"ok","timestamp":1615900529636,"user_tz":240,"elapsed":8912,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}}},"source":["%%capture\n","try:\n","    from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup, BertTokenizer\n","except ModuleNotFoundError:\n","    !pip install transformers\n","    from transformers import AdamW, BertConfig, get_linear_schedule_with_warmup, BertTokenizer\n","    "],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["0cedafacfc7a4151b9050251ca0726df","2fc4717a13424378b2fe43085c42c93a","319ff408158241b7afb705e55b079609","7931d6ef685742889ca65bf20ff1bc3d","76c87573d66d4a99a123f4ba19493603","0007674eb5434be181bc23dba8dfa73c","d7f30259b088435c926072b2e1b0506a","82050b52082a44b5a051179169d0daa1"]},"id":"tnpwoarJjKwR","executionInfo":{"status":"ok","timestamp":1615900592987,"user_tz":240,"elapsed":1507,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"af496179-aa07-4a86-8a8b-948e6725eaa7"},"source":["LEARNING_RATE = 1e-4\r\n","ADAMW_TOLERANCE = 1e-8\r\n","BATCH_SIZE = 10\r\n","EPOCHS = 30\r\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\r\n","VOCAB_SIZE = tokenizer.vocab_size\r\n","LABEL_SIZE =2\r\n","HIDDEN_DIM = 200\r\n","EMBEDDING_DIM = 100\r\n","N_RNN_LAYERS = 2\r\n","\r\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\r\n","print(\"Running on '%s'.\" % device)"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0cedafacfc7a4151b9050251ca0726df","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Running on 'cuda'.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WZElNobPHeTq","executionInfo":{"status":"ok","timestamp":1615900604851,"user_tz":240,"elapsed":948,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"be1ee33f-88ad-4bab-baae-711f6ea9c331"},"source":["train_dataloader, validation_dataloader, test_dataloader = generate_dataloaders(BATCH_SIZE)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["6,919 training samples.\n","  876 validation samples.\n","1,822 test samples.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gH6eB7B-mCC6","executionInfo":{"status":"ok","timestamp":1615900639488,"user_tz":240,"elapsed":9171,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}}},"source":["model = LSTM(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, LABEL_SIZE, N_RNN_LAYERS).to(device)\r\n","save_filename = \"lstm_sst2\"\r\n","optimizer = AdamW(model.parameters(), lr = LEARNING_RATE, eps = ADAMW_TOLERANCE)\r\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = EPOCHS * BATCH_SIZE * len(train_dataloader))"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J5XK8r6uyz5a","executionInfo":{"status":"ok","timestamp":1615901551419,"user_tz":240,"elapsed":903711,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"de6c299e-340d-4f7a-f060-826fedfe2775"},"source":["try:\r\n","    train(model, EPOCHS, train_dataloader, validation_dataloader, optimizer, scheduler, save_dir, save_filename, device)\r\n","except KeyboardInterrupt:\r\n","    print(\"Graceful Exit\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:04.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:09.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:14.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.69\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.55\n","  Validation Loss: 0.68\n","  Validation took: 0:00:01\n","\n","======== Epoch 2 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:18.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.66\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.66\n","  Validation Loss: 0.62\n","  Validation took: 0:00:01\n","\n","======== Epoch 3 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:18.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:23.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.63\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.67\n","  Validation Loss: 0.61\n","  Validation took: 0:00:01\n","\n","======== Epoch 4 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:18.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.60\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.70\n","  Validation Loss: 0.59\n","  Validation took: 0:00:01\n","\n","======== Epoch 5 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:18.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.58\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.71\n","  Validation Loss: 0.56\n","  Validation took: 0:00:01\n","\n","======== Epoch 6 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.56\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.55\n","  Validation took: 0:00:01\n","\n","======== Epoch 7 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.54\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.53\n","  Validation took: 0:00:01\n","\n","======== Epoch 8 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.50\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.72\n","  Validation Loss: 0.58\n","  Validation took: 0:00:01\n","\n","======== Epoch 9 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:14.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.46\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.74\n","  Validation Loss: 0.52\n","  Validation took: 0:00:01\n","\n","======== Epoch 10 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.44\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.76\n","  Validation Loss: 0.53\n","  Validation took: 0:00:01\n","\n","======== Epoch 11 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.41\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.50\n","  Validation took: 0:00:01\n","\n","======== Epoch 12 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.39\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.51\n","  Validation took: 0:00:01\n","\n","======== Epoch 13 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.36\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 14 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.34\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.76\n","  Validation Loss: 0.53\n","  Validation took: 0:00:01\n","\n","======== Epoch 15 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.33\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.76\n","  Validation Loss: 0.51\n","  Validation took: 0:00:01\n","\n","======== Epoch 16 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.31\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.76\n","  Validation Loss: 0.55\n","  Validation took: 0:00:01\n","\n","======== Epoch 17 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.30\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.54\n","  Validation took: 0:00:01\n","\n","======== Epoch 18 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.28\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.59\n","  Validation took: 0:00:01\n","\n","======== Epoch 19 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.26\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.57\n","  Validation took: 0:00:01\n","\n","======== Epoch 20 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.26\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.64\n","  Validation took: 0:00:01\n","\n","======== Epoch 21 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.25\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.76\n","  Validation Loss: 0.59\n","  Validation took: 0:00:01\n","\n","======== Epoch 22 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.24\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.78\n","  Validation Loss: 0.59\n","  Validation took: 0:00:01\n","\n","======== Epoch 23 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.22\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.62\n","  Validation took: 0:00:01\n","\n","======== Epoch 24 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.22\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.58\n","  Validation took: 0:00:01\n","\n","======== Epoch 25 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:18.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.21\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.78\n","  Validation took: 0:00:01\n","\n","======== Epoch 26 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.20\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.61\n","  Validation took: 0:00:01\n","\n","======== Epoch 27 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:19.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.19\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.77\n","  Validation Loss: 0.63\n","  Validation took: 0:00:01\n","\n","======== Epoch 28 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:18.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.18\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.72\n","  Validation took: 0:00:01\n","\n","======== Epoch 29 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:18.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.16\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.76\n","  Validation Loss: 0.77\n","  Validation took: 0:00:01\n","\n","======== Epoch 30 / 30 ========\n","Training...\n","  Batch    40  of    692.    Elapsed: 0:00:02.\n","  Batch    80  of    692.    Elapsed: 0:00:03.\n","  Batch   120  of    692.    Elapsed: 0:00:05.\n","  Batch   160  of    692.    Elapsed: 0:00:07.\n","  Batch   200  of    692.    Elapsed: 0:00:08.\n","  Batch   240  of    692.    Elapsed: 0:00:10.\n","  Batch   280  of    692.    Elapsed: 0:00:12.\n","  Batch   320  of    692.    Elapsed: 0:00:13.\n","  Batch   360  of    692.    Elapsed: 0:00:15.\n","  Batch   400  of    692.    Elapsed: 0:00:17.\n","  Batch   440  of    692.    Elapsed: 0:00:18.\n","  Batch   480  of    692.    Elapsed: 0:00:20.\n","  Batch   520  of    692.    Elapsed: 0:00:22.\n","  Batch   560  of    692.    Elapsed: 0:00:24.\n","  Batch   600  of    692.    Elapsed: 0:00:25.\n","  Batch   640  of    692.    Elapsed: 0:00:27.\n","  Batch   680  of    692.    Elapsed: 0:00:29.\n","\n","  Average training loss: 0.16\n","  Training epcoh took: 0:00:29\n","\n","Running Validation...\n","  Accuracy: 0.75\n","  Validation Loss: 0.76\n","  Validation took: 0:00:01\n","\n","Training complete!\n","Total training took 0:15:02 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iEDOepJ8l-WD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615901553495,"user_tz":240,"elapsed":869264,"user":{"displayName":"Ronak Mehta","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgvL0OEKDdfWJnnCVVtFTsqSBT6-uRCtSdS5vM7MA=s64","userId":"12475517112718652159"}},"outputId":"97bf66d4-4562-4bcd-aa33-c40b5da83ee6"},"source":["test(model, test_dataloader, device, save_dir, save_filename)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["\n","Testing...\n","  Accuracy: 0.77\n","  Test Loss: 0.76\n","  Test took: 0:00:02\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NtiRf4CgL696"},"source":[""],"execution_count":null,"outputs":[]}]}